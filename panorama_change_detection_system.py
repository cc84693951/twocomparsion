#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨æ™¯å›¾åƒå˜åŒ–æ£€æµ‹ç³»ç»Ÿ
åˆå¹¶å…¨æ™¯å›¾å¤„ç†å’Œå›¾åƒå˜åŒ–æ£€æµ‹åŠŸèƒ½
å®ç°å®Œæ•´çš„å…¨æ™¯å›¾åƒå˜åŒ–æ£€æµ‹æµç¨‹

ä¸»è¦åŠŸèƒ½ï¼š
1. å…¨æ™¯å›¾ç«‹æ–¹ä½“åˆ†å‰²
2. å›¾åƒé¢„å¤„ç†ï¼ˆå»å™ªã€ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼‰
3. AKAZEç‰¹å¾ç‚¹æå–å’ŒåŒ¹é…
4. å›¾åƒé…å‡†å’Œå˜æ¢
5. å›¾åƒå·®åˆ†è®¡ç®—
6. é˜ˆå€¼åˆ†å‰²å’Œå½¢æ€å­¦æ“ä½œ
7. è½®å»“æå–å’Œè¿‡æ»¤
8. ç›®æ ‡æ£€æµ‹æ¡†ç”Ÿæˆ
9. ç»“æœè¿˜åŸè‡³å…¨æ™¯å›¾

ä½œè€…ï¼šAI Assistant
æ—¥æœŸï¼š2025å¹´09æœˆ18æ—¥
"""

import cv2
import numpy as np
import os
import json
import math
import random
from datetime import datetime
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.patches as patches

# CUDAæ”¯æŒæ£€æµ‹
try:
    import cupy as cp
    CUDA_AVAILABLE = True
    print("âœ… CUDAæ”¯æŒå·²å¯ç”¨")
except ImportError:
    CUDA_AVAILABLE = False
    print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUç‰ˆæœ¬")
    # åˆ›å»ºCuPyçš„æ›¿ä»£å®ç°
    class cp:
        @staticmethod
        def array(x):
            return np.array(x)
        @staticmethod
        def asnumpy(x):
            return np.array(x)
        @staticmethod
        def asarray(x):
            return np.array(x)
        @staticmethod
        def zeros_like(x):
            return np.zeros_like(x)
        @staticmethod
        def zeros(shape, dtype=None):
            return np.zeros(shape, dtype=dtype)
        @staticmethod
        def ones_like(x):
            return np.ones_like(x)
        @staticmethod
        def sqrt(x):
            return np.sqrt(x)
        @staticmethod
        def sin(x):
            return np.sin(x)
        @staticmethod
        def cos(x):
            return np.cos(x)
        @staticmethod
        def arctan2(x, y):
            return np.arctan2(x, y)
        @staticmethod
        def arccos(x):
            return np.arccos(x)
        @staticmethod
        def meshgrid(*args, **kwargs):
            return np.meshgrid(*args, **kwargs)
        @staticmethod
        def arange(*args, **kwargs):
            return np.arange(*args, **kwargs)
        @staticmethod
        def stack(*args, **kwargs):
            return np.stack(*args, **kwargs)
        @staticmethod
        def abs(x):
            return np.abs(x)
        @staticmethod
        def any(x):
            return np.any(x)
        @staticmethod
        def floor(x):
            return np.floor(x)
        @staticmethod
        def clip(x, a_min, a_max):
            return np.clip(x, a_min, a_max)
        @staticmethod
        def where(condition, x, y):
            return np.where(condition, x, y)
        pi = np.pi
        uint8 = np.uint8
        float32 = np.float32
        int32 = np.int32


class PanoramaChangeDetectionSystem:
    """å…¨æ™¯å›¾åƒå˜åŒ–æ£€æµ‹ç³»ç»Ÿ"""
    
    def __init__(self, output_dir="panorama_change_detection_results", use_cuda=True):
        """
        åˆå§‹åŒ–ç³»ç»Ÿ
        
        Args:
            output_dir (str): è¾“å‡ºç›®å½•
            use_cuda (bool): æ˜¯å¦ä½¿ç”¨CUDAåŠ é€Ÿ
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # ç«‹æ–¹ä½“é¢åç§°å’Œæè¿°
        self.face_names = ['front', 'right', 'back', 'left', 'top', 'bottom']
        self.face_descriptions = {
            'front': 'å‰é¢', 'right': 'å³é¢', 'back': 'åé¢',
            'left': 'å·¦é¢', 'top': 'ä¸Šé¢', 'bottom': 'ä¸‹é¢'
        }
        
        # CUDAè®¾ç½®
        self.use_cuda = use_cuda and CUDA_AVAILABLE
        if self.use_cuda:
            try:
                cp.cuda.Device(0).use()
                print("ğŸš€ GPUåŠ é€Ÿå·²å¯ç”¨")
                print("  â”œâ”€ ç«‹æ–¹ä½“åˆ†å‰²: CUDAåŠ é€Ÿ")
                print("  â”œâ”€ å›¾åƒé¢„å¤„ç†: CUDAåŠ é€Ÿ")
                print("  â”œâ”€ å›¾åƒå·®åˆ†: CUDAåŠ é€Ÿ")
                print("  â”œâ”€ å½¢æ€å­¦æ“ä½œ: CUDAåŠ é€Ÿ")
                print("  â”œâ”€ å…¨æ™¯å›¾é‡å»º: CUDAåŠ é€Ÿ")
                print("  â””â”€ åŒçº¿æ€§æ’å€¼: CUDAåŠ é€Ÿ")
            except Exception:
                self.use_cuda = False
                print("âš ï¸ GPUåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨CPUç‰ˆæœ¬")
        
        # ç³»ç»Ÿå‚æ•°é…ç½®
        self.config = {
            'cube_size': None,                    # ç«‹æ–¹ä½“é¢å°ºå¯¸ï¼ˆåŠ¨æ€è®¡ç®—ï¼‰
            'diff_threshold': 30,                 # å·®å¼‚é˜ˆå€¼
            'min_contour_area': 500,              # æœ€å°è½®å»“é¢ç§¯
            'max_contour_area': 50000,            # æœ€å¤§è½®å»“é¢ç§¯
            'min_aspect_ratio': 0.2,              # æœ€å°é•¿å®½æ¯”
            'max_aspect_ratio': 5.0,              # æœ€å¤§é•¿å®½æ¯”
            'morphology_kernel_size': (5, 5),     # å½¢æ€å­¦æ ¸å¤§å°
            'gaussian_blur_kernel': (3, 3),       # é«˜æ–¯æ¨¡ç³Šæ ¸å¤§å°
            'clahe_clip_limit': 2.0,              # CLAHEé™åˆ¶å€¼
            'clahe_tile_grid_size': (8, 8),       # CLAHEç½‘æ ¼å¤§å°
            'skip_faces': ['top'],                # è·³è¿‡çš„é¢
        }
        
        print(f"ğŸ”§ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"âš™ï¸ ç³»ç»Ÿé…ç½®: {self.config}")
    
    def load_image_with_chinese_path(self, path):
        """
        åŠ è½½åŒ…å«ä¸­æ–‡è·¯å¾„çš„å›¾åƒ
        
        Args:
            path (str): å›¾åƒè·¯å¾„
            
        Returns:
            ndarray: å›¾åƒæ•°æ®
        """
        try:
            img_array = np.fromfile(path, dtype=np.uint8)
            img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
            if img is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {path}")
            return img
        except Exception as e:
            print(f"âŒ è¯»å–å›¾åƒå¤±è´¥ {path}: {str(e)}")
            return None
    
    def panorama_to_cubemap(self, panorama_img, cube_size=None):
        """
        å…¨æ™¯å›¾è½¬æ¢ä¸ºç«‹æ–¹ä½“è´´å›¾
        
        Args:
            panorama_img (ndarray): å…¨æ™¯å›¾åƒ
            cube_size (int): ç«‹æ–¹ä½“é¢å°ºå¯¸ï¼Œå¦‚æœä¸ºNoneåˆ™åŠ¨æ€è®¡ç®—
            
        Returns:
            dict: ç«‹æ–¹ä½“é¢å­—å…¸
        """
        print("ğŸ”„ å¼€å§‹å…¨æ™¯å›¾ç«‹æ–¹ä½“åˆ†å‰²...")
        height, width = panorama_img.shape[:2]
        
        # åŠ¨æ€è®¡ç®—æœ€ä½³ç«‹æ–¹ä½“é¢å°ºå¯¸
        if cube_size is None:
            # åŸºäºå…¨æ™¯å›¾å°ºå¯¸è®¡ç®—ï¼Œä¿æŒé«˜åˆ†è¾¨ç‡
            cube_size = min(width // 4, height // 2)  # ç¡®ä¿ä¸ä¼šå¤ªå¤§å¯¼è‡´å†…å­˜é—®é¢˜
            cube_size = max(cube_size, 1024)  # æœ€å°1024
            cube_size = min(cube_size, 4096)  # æœ€å¤§4096
        
        print(f"ğŸ“ ä½¿ç”¨ç«‹æ–¹ä½“é¢å°ºå¯¸: {cube_size}Ã—{cube_size}")
        print(f"ğŸ“Š åŸå›¾å°ºå¯¸: {width}Ã—{height}")
        
        # æ›´æ–°é…ç½®ä¸­çš„cube_size
        self.config['cube_size'] = cube_size
        
        faces = {}
        
        if self.use_cuda:
            faces = self._panorama_to_cubemap_cuda(panorama_img, cube_size, height, width)
        else:
            faces = self._panorama_to_cubemap_cpu(panorama_img, cube_size, height, width)
        
        print(f"âœ… ç«‹æ–¹ä½“åˆ†å‰²å®Œæˆï¼Œç”Ÿæˆ {len(faces)} ä¸ªé¢")
        return faces
    
    def _panorama_to_cubemap_cuda(self, panorama_img, cube_size, height, width):
        """CUDAåŠ é€Ÿçš„å…¨æ™¯å›¾è½¬æ¢"""
        faces = {}
        
        # å°†å…¨æ™¯å›¾ä¼ è¾“åˆ°GPU
        panorama_gpu = cp.asarray(panorama_img)
        
        # ç”Ÿæˆåæ ‡ç½‘æ ¼
        row_coords, col_coords = cp.meshgrid(cp.arange(cube_size), cp.arange(cube_size), indexing='ij')
        
        for i, face_name in enumerate(tqdm(self.face_names, desc="CUDAè½¬æ¢ç«‹æ–¹ä½“é¢")):
            # æ ‡å‡†åŒ–åæ ‡åˆ°[-1, 1]
            x = (2.0 * col_coords / cube_size) - 1.0
            y = (2.0 * row_coords / cube_size) - 1.0
            
            # æ ¹æ®é¢ç±»å‹è®¡ç®—3Dåæ ‡
            if i == 0:    # front
                x3d, y3d, z3d = x, -y, cp.ones_like(x)
            elif i == 1:  # right
                x3d, y3d, z3d = cp.ones_like(x), -y, -x
            elif i == 2:  # back
                x3d, y3d, z3d = -x, -y, -cp.ones_like(x)
            elif i == 3:  # left
                x3d, y3d, z3d = -cp.ones_like(x), -y, x
            elif i == 4:  # top
                x3d, y3d, z3d = x, cp.ones_like(x), y
            elif i == 5:  # bottom
                x3d, y3d, z3d = x, -cp.ones_like(x), y
            
            # è½¬æ¢ä¸ºçƒé¢åæ ‡
            r = cp.sqrt(x3d*x3d + y3d*y3d + z3d*z3d)
            theta = cp.arctan2(x3d, z3d)
            phi = cp.arccos(y3d / r)
            
            # è½¬æ¢ä¸ºå…¨æ™¯å›¾åæ ‡
            u = (theta + cp.pi) / (2 * cp.pi) * width
            v = phi / cp.pi * height
            
            # è¾¹ç•Œæ£€æŸ¥
            valid_mask = (u >= 0) & (u < width) & (v >= 0) & (v < height)
            
            # ä½¿ç”¨GPUåŒçº¿æ€§æ’å€¼é‡‡æ ·
            face_img_gpu = self._cuda_bilinear_sample(panorama_gpu, u, v, valid_mask, cube_size)
            
            # ä¼ è¾“å›CPU
            faces[face_name] = cp.asnumpy(face_img_gpu)
        
        return faces
    
    def _panorama_to_cubemap_cpu(self, panorama_img, cube_size, height, width):
        """CPUç‰ˆæœ¬çš„å…¨æ™¯å›¾è½¬æ¢"""
        faces = {}
        
        for i, face_name in enumerate(tqdm(self.face_names, desc="CPUè½¬æ¢ç«‹æ–¹ä½“é¢")):
            face_img = np.zeros((cube_size, cube_size, 3), dtype=np.uint8)
            
            for row in range(cube_size):
                for col in range(cube_size):
                    # æ ‡å‡†åŒ–åæ ‡åˆ°[-1, 1]
                    x = (2.0 * col / cube_size) - 1.0
                    y = (2.0 * row / cube_size) - 1.0
                    
                    # æ ¹æ®é¢ç±»å‹è®¡ç®—3Dåæ ‡
                    if i == 0:    # front
                        xyz = [x, -y, 1.0]
                    elif i == 1:  # right
                        xyz = [1.0, -y, -x]
                    elif i == 2:  # back
                        xyz = [-x, -y, -1.0]
                    elif i == 3:  # left
                        xyz = [-1.0, -y, x]
                    elif i == 4:  # top
                        xyz = [x, 1.0, y]
                    elif i == 5:  # bottom
                        xyz = [x, -1.0, y]
                    
                    # è½¬æ¢ä¸ºçƒé¢åæ ‡
                    x3d, y3d, z3d = xyz
                    r = math.sqrt(x3d*x3d + y3d*y3d + z3d*z3d)
                    theta = math.atan2(x3d, z3d)
                    phi = math.acos(y3d / r)
                    
                    # è½¬æ¢ä¸ºå…¨æ™¯å›¾åæ ‡
                    u = (theta + math.pi) / (2 * math.pi) * width
                    v = phi / math.pi * height
                    
                    # è¾¹ç•Œæ£€æŸ¥å’Œåƒç´ é‡‡æ ·
                    if 0 <= u < width and 0 <= v < height:
                        face_img[row, col] = panorama_img[int(v), int(u)]
            
            faces[face_name] = face_img
        
        return faces
    
    def _cuda_bilinear_sample(self, img_gpu, u, v, valid_mask, cube_size):
        """CUDAåŒçº¿æ€§æ’å€¼é‡‡æ ·"""
        valid_indices = cp.where(valid_mask)
        if len(valid_indices[0]) == 0:
            return cp.zeros((cube_size, cube_size, 3), dtype=cp.uint8)
        
        face_img = cp.zeros((cube_size, cube_size, 3), dtype=cp.uint8)
        
        u_valid = u[valid_mask]
        v_valid = v[valid_mask]
        
        u_int = cp.floor(u_valid).astype(cp.int32)
        v_int = cp.floor(v_valid).astype(cp.int32)
        u_frac = u_valid - u_int
        v_frac = v_valid - v_int
        
        height, width = img_gpu.shape[:2]
        u_int = cp.clip(u_int, 0, width - 2)
        v_int = cp.clip(v_int, 0, height - 2)
        
        for c in range(3):
            p00 = img_gpu[v_int, u_int, c]
            p01 = img_gpu[v_int, u_int + 1, c]
            p10 = img_gpu[v_int + 1, u_int, c]
            p11 = img_gpu[v_int + 1, u_int + 1, c]
            
            interpolated = (p00 * (1 - u_frac) * (1 - v_frac) +
                          p01 * u_frac * (1 - v_frac) +
                          p10 * (1 - u_frac) * v_frac +
                          p11 * u_frac * v_frac)
            
            face_img[valid_indices[0], valid_indices[1], c] = interpolated
        
        return face_img
    
    def preprocess_image(self, img):
        """
        å›¾åƒé¢„å¤„ç†ï¼šå»å™ªå’Œç›´æ–¹å›¾å‡è¡¡åŒ–
        
        Args:
            img (ndarray): è¾“å…¥å›¾åƒ
            
        Returns:
            ndarray: é¢„å¤„ç†åçš„å›¾åƒ
        """
        if self.use_cuda and CUDA_AVAILABLE:
            return self._preprocess_image_cuda(img)
        else:
            return self._preprocess_image_cpu(img)
    
    def _preprocess_image_cuda(self, img):
        """CUDAåŠ é€Ÿçš„å›¾åƒé¢„å¤„ç†"""
        try:
            # ä¼ è¾“åˆ°GPU
            img_gpu = cp.asarray(img)
            
            # 1. GPUé«˜æ–¯æ¨¡ç³Š (ä½¿ç”¨CuPyçš„filterå®ç°)
            kernel_size = self.config['gaussian_blur_kernel'][0]
            if kernel_size % 2 == 0:
                kernel_size += 1
            
            # ç®€åŒ–çš„é«˜æ–¯æ¨¡ç³Šï¼ˆä½¿ç”¨å‡å€¼æ»¤æ³¢è¿‘ä¼¼ï¼‰
            from cupyx.scipy import ndimage
            denoised_gpu = ndimage.gaussian_filter(img_gpu.astype(cp.float32), sigma=1.0)
            denoised_gpu = cp.clip(denoised_gpu, 0, 255).astype(cp.uint8)
            
            # 2. é¢œè‰²ç©ºé—´è½¬æ¢åˆ°LABï¼ˆåœ¨GPUä¸Šï¼‰
            # CuPyæ²¡æœ‰ç›´æ¥çš„é¢œè‰²ç©ºé—´è½¬æ¢ï¼Œå›é€€åˆ°CPUå¤„ç†é¢œè‰²ç©ºé—´
            denoised = cp.asnumpy(denoised_gpu)
            lab = cv2.cvtColor(denoised, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            # 3. CLAHEå¤„ç†ï¼ˆCPUï¼Œå› ä¸ºOpenCVçš„CLAHEæ²¡æœ‰GPUç‰ˆæœ¬ï¼‰
            clahe = cv2.createCLAHE(
                clipLimit=self.config['clahe_clip_limit'], 
                tileGridSize=self.config['clahe_tile_grid_size']
            )
            l_clahe = clahe.apply(l)
            
            # 4. åˆå¹¶é€šé“å¹¶è½¬å›BGR
            lab_clahe = cv2.merge([l_clahe, a, b])
            processed = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)
            
            return processed
            
        except Exception as e:
            print(f"âš ï¸ CUDAé¢„å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}")
            return self._preprocess_image_cpu(img)
    
    def _preprocess_image_cpu(self, img):
        """CPUç‰ˆæœ¬çš„å›¾åƒé¢„å¤„ç†"""
        # 1. é«˜æ–¯æ¨¡ç³Šå»å™ª
        denoised = cv2.GaussianBlur(img, self.config['gaussian_blur_kernel'], 0)
        
        # 2. è½¬æ¢ä¸ºLABé¢œè‰²ç©ºé—´è¿›è¡ŒCLAHEå¤„ç†
        lab = cv2.cvtColor(denoised, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        
        # 3. å¯¹Lé€šé“åº”ç”¨CLAHE
        clahe = cv2.createCLAHE(
            clipLimit=self.config['clahe_clip_limit'], 
            tileGridSize=self.config['clahe_tile_grid_size']
        )
        l_clahe = clahe.apply(l)
        
        # 4. åˆå¹¶é€šé“å¹¶è½¬å›BGR
        lab_clahe = cv2.merge([l_clahe, a, b])
        processed = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)
        
        return processed
    
    def extract_akaze_features(self, img):
        """
        ä½¿ç”¨AKAZEç®—æ³•æå–å›¾åƒç‰¹å¾ç‚¹
        
        Args:
            img (ndarray): è¾“å…¥å›¾åƒ
            
        Returns:
            tuple: (å…³é”®ç‚¹, æè¿°ç¬¦)
        """
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
        
        # åˆ›å»ºAKAZEæ£€æµ‹å™¨
        akaze = cv2.AKAZE_create()
        
        # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦
        keypoints, descriptors = akaze.detectAndCompute(gray, None)
        
        return keypoints, descriptors
    
    def match_features_and_register(self, img1, img2, kp1, des1, kp2, des2):
        """
        ç‰¹å¾åŒ¹é…å’Œå›¾åƒé…å‡†
        
        Args:
            img1, img2: è¾“å…¥å›¾åƒ
            kp1, des1: ç¬¬ä¸€å¼ å›¾åƒçš„å…³é”®ç‚¹å’Œæè¿°ç¬¦
            kp2, des2: ç¬¬äºŒå¼ å›¾åƒçš„å…³é”®ç‚¹å’Œæè¿°ç¬¦
            
        Returns:
            tuple: (é…å‡†åçš„å›¾åƒ2, å•åº”æ€§çŸ©é˜µ, åŒ¹é…ä¿¡æ¯)
        """
        if des1 is None or des2 is None or len(kp1) < 4 or len(kp2) < 4:
            print("âš ï¸ ç‰¹å¾ç‚¹ä¸è¶³ï¼Œè·³è¿‡é…å‡†")
            return img2, None, {"matches": 0, "inliers": 0, "inlier_ratio": 0.0}
        
        # ä½¿ç”¨BFMatcherè¿›è¡Œç‰¹å¾åŒ¹é…
        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        matches = bf.match(des1, des2)
        
        # æŒ‰è·ç¦»æ’åº
        matches = sorted(matches, key=lambda x: x.distance)
        
        if len(matches) < 4:
            print("âš ï¸ åŒ¹é…ç‚¹ä¸è¶³ï¼Œè·³è¿‡é…å‡†")
            return img2, None, {"matches": len(matches), "inliers": 0, "inlier_ratio": 0.0}
        
        # æå–åŒ¹é…ç‚¹åæ ‡
        src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)
        
        # ä½¿ç”¨RANSACè®¡ç®—å•åº”æ€§çŸ©é˜µ
        homography, mask = cv2.findHomography(
            dst_pts, src_pts, 
            cv2.RANSAC, 
            ransacReprojThreshold=5.0
        )
        
        if homography is None:
            print("âš ï¸ æ— æ³•è®¡ç®—å•åº”æ€§çŸ©é˜µ")
            return img2, None, {"matches": len(matches), "inliers": 0, "inlier_ratio": 0.0}
        
        # è®¡ç®—å†…ç‚¹æ•°é‡
        inliers = np.sum(mask) if mask is not None else 0
        
        # åº”ç”¨å•åº”æ€§å˜æ¢
        h, w = img1.shape[:2]
        registered_img2 = cv2.warpPerspective(img2, homography, (w, h))
        
        match_info = {
            "matches": len(matches),
            "inliers": int(inliers),
            "inlier_ratio": float(inliers / len(matches)) if len(matches) > 0 else 0.0,
            "homography": homography.tolist() if homography is not None else None
        }
        
        print(f"âœ… ç‰¹å¾åŒ¹é…å®Œæˆï¼š{len(matches)} ä¸ªåŒ¹é…ç‚¹ï¼Œ{inliers} ä¸ªå†…ç‚¹")
        
        return registered_img2, homography, match_info
    
    def compute_image_difference(self, img1, img2):
        """
        è®¡ç®—å›¾åƒå·®åˆ†
        
        Args:
            img1, img2: è¾“å…¥å›¾åƒ
            
        Returns:
            ndarray: å·®åˆ†å›¾åƒ
        """
        if self.use_cuda and CUDA_AVAILABLE:
            return self._compute_image_difference_cuda(img1, img2)
        else:
            return self._compute_image_difference_cpu(img1, img2)
    
    def _compute_image_difference_cuda(self, img1, img2):
        """CUDAåŠ é€Ÿçš„å›¾åƒå·®åˆ†è®¡ç®—"""
        try:
            # ä¼ è¾“åˆ°GPU
            img1_gpu = cp.asarray(img1)
            img2_gpu = cp.asarray(img2)
            
            # è½¬æ¢ä¸ºç°åº¦å›¾ï¼ˆåœ¨GPUä¸Šï¼‰
            if len(img1_gpu.shape) == 3:
                # RGBåˆ°ç°åº¦çš„æƒé‡ (0.299, 0.587, 0.114)
                weights = cp.array([0.299, 0.587, 0.114])
                gray1_gpu = cp.dot(img1_gpu[...,:3], weights).astype(cp.uint8)
            else:
                gray1_gpu = img1_gpu
                
            if len(img2_gpu.shape) == 3:
                weights = cp.array([0.299, 0.587, 0.114])
                gray2_gpu = cp.dot(img2_gpu[...,:3], weights).astype(cp.uint8)
            else:
                gray2_gpu = img2_gpu
            
            # ç¡®ä¿å°ºå¯¸ä¸€è‡´ï¼ˆåœ¨GPUä¸Šresizeï¼‰
            if gray1_gpu.shape != gray2_gpu.shape:
                # ç®€å•çš„æœ€è¿‘é‚»æ’å€¼resizeï¼ˆGPUç‰ˆæœ¬ï¼‰
                h1, w1 = gray1_gpu.shape
                h2, w2 = gray2_gpu.shape
                if h1 != h2 or w1 != w2:
                    # ä½¿ç”¨GPUçš„resizeåŠŸèƒ½
                    y_scale = h1 / h2
                    x_scale = w1 / w2
                    y_indices = cp.arange(h1)[:, None] / y_scale
                    x_indices = cp.arange(w1)[None, :] / x_scale
                    y_indices = cp.clip(y_indices, 0, h2-1).astype(cp.int32)
                    x_indices = cp.clip(x_indices, 0, w2-1).astype(cp.int32)
                    gray2_gpu = gray2_gpu[y_indices, x_indices]
            
            # è®¡ç®—ç»å¯¹å·®å€¼ï¼ˆåœ¨GPUä¸Šï¼‰
            diff_gpu = cp.abs(gray1_gpu.astype(cp.int16) - gray2_gpu.astype(cp.int16)).astype(cp.uint8)
            
            # ä¼ è¾“å›CPU
            return cp.asnumpy(diff_gpu)
            
        except Exception as e:
            print(f"âš ï¸ CUDAå·®åˆ†è®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}")
            return self._compute_image_difference_cpu(img1, img2)
    
    def _compute_image_difference_cpu(self, img1, img2):
        """CPUç‰ˆæœ¬çš„å›¾åƒå·®åˆ†è®¡ç®—"""
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) if len(img1.shape) == 3 else img1
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) if len(img2.shape) == 3 else img2
        
        # ç¡®ä¿å°ºå¯¸ä¸€è‡´
        if gray1.shape != gray2.shape:
            gray2 = cv2.resize(gray2, (gray1.shape[1], gray1.shape[0]))
        
        # è®¡ç®—ç»å¯¹å·®å€¼
        diff = cv2.absdiff(gray1, gray2)
        
        return diff
    
    def threshold_and_morphology(self, diff_img):
        """
        é˜ˆå€¼åˆ†å‰²å’Œå½¢æ€å­¦æ“ä½œ
        
        Args:
            diff_img: å·®åˆ†å›¾åƒ
            
        Returns:
            ndarray: å¤„ç†åçš„äºŒå€¼å›¾åƒ
        """
        if self.use_cuda and CUDA_AVAILABLE:
            return self._threshold_and_morphology_cuda(diff_img)
        else:
            return self._threshold_and_morphology_cpu(diff_img)
    
    def _threshold_and_morphology_cuda(self, diff_img):
        """CUDAåŠ é€Ÿçš„é˜ˆå€¼åˆ†å‰²å’Œå½¢æ€å­¦æ“ä½œ"""
        try:
            # ä¼ è¾“åˆ°GPU
            diff_gpu = cp.asarray(diff_img)
            
            # é˜ˆå€¼åˆ†å‰²ï¼ˆåœ¨GPUä¸Šï¼‰
            binary_gpu = (diff_gpu > self.config['diff_threshold']).astype(cp.uint8) * 255
            
            # å½¢æ€å­¦æ“ä½œï¼ˆä½¿ç”¨CuPyçš„ndimageï¼‰
            from cupyx.scipy import ndimage
            
            # åˆ›å»ºæ¤­åœ†å½¢ç»“æ„å…ƒç´ 
            kernel_size = self.config['morphology_kernel_size']
            y, x = cp.ogrid[-kernel_size[0]//2:kernel_size[0]//2+1, -kernel_size[1]//2:kernel_size[1]//2+1]
            kernel = ((x*x)/(kernel_size[1]//2)**2 + (y*y)/(kernel_size[0]//2)**2) <= 1
            kernel = kernel.astype(cp.uint8)
            
            # é—­è¿ç®—ï¼šå…ˆè†¨èƒ€åè…èš€
            dilated = ndimage.binary_dilation(binary_gpu > 0, structure=kernel).astype(cp.uint8) * 255
            closed = ndimage.binary_erosion(dilated > 0, structure=kernel).astype(cp.uint8) * 255
            
            # å¼€è¿ç®—ï¼šå…ˆè…èš€åè†¨èƒ€
            eroded = ndimage.binary_erosion(closed > 0, structure=kernel).astype(cp.uint8) * 255
            opened = ndimage.binary_dilation(eroded > 0, structure=kernel).astype(cp.uint8) * 255
            
            # ä¼ è¾“å›CPU
            return cp.asnumpy(opened)
            
        except Exception as e:
            print(f"âš ï¸ CUDAå½¢æ€å­¦æ“ä½œå¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}")
            return self._threshold_and_morphology_cpu(diff_img)
    
    def _threshold_and_morphology_cpu(self, diff_img):
        """CPUç‰ˆæœ¬çš„é˜ˆå€¼åˆ†å‰²å’Œå½¢æ€å­¦æ“ä½œ"""
        # é˜ˆå€¼åˆ†å‰²
        _, binary = cv2.threshold(diff_img, self.config['diff_threshold'], 255, cv2.THRESH_BINARY)
        
        # å½¢æ€å­¦æ“ä½œ
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, self.config['morphology_kernel_size'])
        
        # å…ˆé—­è¿ç®—è¿æ¥é‚»è¿‘åŒºåŸŸ
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # å†å¼€è¿ç®—å»é™¤å™ªå£°
        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
        
        return binary
    
    def extract_contours_and_bboxes(self, binary_img, original_img):
        """
        è½®å»“æå–å’Œè¾¹ç•Œæ¡†ç”Ÿæˆ
        
        Args:
            binary_img: äºŒå€¼å›¾åƒ
            original_img: åŸå§‹å›¾åƒï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
            
        Returns:
            tuple: (è¾¹ç•Œæ¡†åˆ—è¡¨, å¯è§†åŒ–å›¾åƒ)
        """
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        bboxes = []
        vis_img = original_img.copy()
        
        for i, contour in enumerate(contours):
            area = cv2.contourArea(contour)
            
            # é¢ç§¯è¿‡æ»¤
            if area < self.config['min_contour_area'] or area > self.config['max_contour_area']:
                continue
            
            # è®¡ç®—è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # é•¿å®½æ¯”è¿‡æ»¤
            aspect_ratio = max(w, h) / min(w, h)
            if aspect_ratio < self.config['min_aspect_ratio'] or aspect_ratio > self.config['max_aspect_ratio']:
                continue
            
            # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºé¢ç§¯å’Œå½¢çŠ¶ï¼‰
            perimeter = cv2.arcLength(contour, True)
            if perimeter == 0:
                continue
                
            circularity = 4 * np.pi * area / (perimeter * perimeter)
            confidence = min(1.0, area / 10000.0 * circularity)
            
            bbox_info = {
                'id': i + 1,
                'bbox': [int(x), int(y), int(w), int(h)],
                'area': float(area),
                'aspect_ratio': float(aspect_ratio),
                'circularity': float(circularity),
                'confidence': float(confidence),
                'center': [int(x + w/2), int(y + h/2)]
            }
            
            bboxes.append(bbox_info)
            
            # åœ¨å¯è§†åŒ–å›¾åƒä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†
            color = (0, 255, 0) if confidence > 0.7 else (0, 255, 255) if confidence > 0.5 else (255, 0, 0)
            cv2.rectangle(vis_img, (x, y), (x+w, y+h), color, 2)
            cv2.putText(vis_img, f"ID:{i+1} ({confidence:.2f})", 
                       (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        bboxes.sort(key=lambda x: x['confidence'], reverse=True)
        
        print(f"âœ… æ£€æµ‹åˆ° {len(bboxes)} ä¸ªæœ‰æ•ˆå˜åŒ–åŒºåŸŸ")
        
        return bboxes, vis_img
    
    def map_bboxes_to_panorama(self, face_bboxes, face_name, cube_size, panorama_width, panorama_height):
        """
        å°†ç«‹æ–¹ä½“é¢çš„è¾¹ç•Œæ¡†æ˜ å°„å›å…¨æ™¯å›¾
        
        Args:
            face_bboxes: ç«‹æ–¹ä½“é¢çš„è¾¹ç•Œæ¡†åˆ—è¡¨
            face_name: é¢åç§°
            cube_size: ç«‹æ–¹ä½“é¢å°ºå¯¸
            panorama_width: å…¨æ™¯å›¾å®½åº¦
            panorama_height: å…¨æ™¯å›¾é«˜åº¦
            
        Returns:
            list: æ˜ å°„åˆ°å…¨æ™¯å›¾çš„è¾¹ç•Œæ¡†åˆ—è¡¨
        """
        if not face_bboxes:
            return []
        
        panorama_bboxes = []
        face_index = self.face_names.index(face_name)
        
        for bbox_info in face_bboxes:
            x, y, w, h = bbox_info['bbox']
            
            # è®¡ç®—è¾¹ç•Œæ¡†çš„å››ä¸ªè§’ç‚¹
            corners = [
                [x, y], [x+w, y], [x+w, y+h], [x, y+h]
            ]
            
            # å°†æ¯ä¸ªè§’ç‚¹æ˜ å°„åˆ°å…¨æ™¯å›¾
            panorama_corners = []
            for corner_x, corner_y in corners:
                pano_x, pano_y = self._face_coord_to_panorama(
                    corner_x, corner_y, face_index, cube_size, panorama_width, panorama_height
                )
                panorama_corners.append([pano_x, pano_y])
            
            # è®¡ç®—å…¨æ™¯å›¾ä¸­çš„è¾¹ç•Œæ¡†
            xs = [c[0] for c in panorama_corners]
            ys = [c[1] for c in panorama_corners]
            
            # å¤„ç†è·¨è¶Šè¾¹ç•Œçš„æƒ…å†µ
            if max(xs) - min(xs) > panorama_width * 0.5:
                # è·¨è¶Šå·¦å³è¾¹ç•Œï¼Œåˆ†æˆä¸¤ä¸ªæ¡†
                left_xs = [x if x < panorama_width/2 else x - panorama_width for x in xs]
                right_xs = [x if x > panorama_width/2 else x + panorama_width for x in xs]
                
                # å·¦ä¾§æ¡†
                left_x1, left_x2 = max(0, min(left_xs)), min(panorama_width-1, max(left_xs))
                if left_x2 > left_x1:
                    y1, y2 = max(0, min(ys)), min(panorama_height-1, max(ys))
                    panorama_bboxes.append({
                        **bbox_info,
                        'face_name': face_name,
                        'panorama_bbox': [int(left_x1), int(y1), int(left_x2-left_x1), int(y2-y1)],
                        'corners': panorama_corners,
                        'split_part': 'left'
                    })
                
                # å³ä¾§æ¡†
                right_x1, right_x2 = max(0, min(right_xs)), min(panorama_width-1, max(right_xs))
                if right_x2 > right_x1:
                    y1, y2 = max(0, min(ys)), min(panorama_height-1, max(ys))
                    panorama_bboxes.append({
                        **bbox_info,
                        'face_name': face_name,
                        'panorama_bbox': [int(right_x1), int(y1), int(right_x2-right_x1), int(y2-y1)],
                        'corners': panorama_corners,
                        'split_part': 'right'
                    })
            else:
                # æ­£å¸¸æƒ…å†µï¼Œä¸è·¨è¶Šè¾¹ç•Œ
                x1, x2 = max(0, min(xs)), min(panorama_width-1, max(xs))
                y1, y2 = max(0, min(ys)), min(panorama_height-1, max(ys))
                
                if x2 > x1 and y2 > y1:
                    panorama_bboxes.append({
                        **bbox_info,
                        'face_name': face_name,
                        'panorama_bbox': [int(x1), int(y1), int(x2-x1), int(y2-y1)],
                        'corners': panorama_corners,
                        'split_part': None
                    })
        
        return panorama_bboxes
    
    def _face_coord_to_panorama(self, face_x, face_y, face_index, cube_size, panorama_width, panorama_height):
        """å°†ç«‹æ–¹ä½“é¢åæ ‡è½¬æ¢ä¸ºå…¨æ™¯å›¾åæ ‡"""
        # æ ‡å‡†åŒ–åˆ°[-1, 1]
        x = (2.0 * face_x / cube_size) - 1.0
        y = (2.0 * face_y / cube_size) - 1.0
        
        # æ ¹æ®é¢ç±»å‹è®¡ç®—3Dåæ ‡
        if face_index == 0:    # front
            xyz = [x, -y, 1.0]
        elif face_index == 1:  # right
            xyz = [1.0, -y, -x]
        elif face_index == 2:  # back
            xyz = [-x, -y, -1.0]
        elif face_index == 3:  # left
            xyz = [-1.0, -y, x]
        elif face_index == 4:  # top
            xyz = [x, 1.0, y]
        elif face_index == 5:  # bottom
            xyz = [x, -1.0, y]
        
        x3d, y3d, z3d = xyz
        
        # è½¬æ¢ä¸ºçƒé¢åæ ‡
        r = math.sqrt(x3d*x3d + y3d*y3d + z3d*z3d)
        theta = math.atan2(x3d, z3d)
        phi = math.acos(y3d / r)
        
        # è½¬æ¢ä¸ºå…¨æ™¯å›¾åæ ‡
        u = (theta + math.pi) / (2 * math.pi) * panorama_width
        v = phi / math.pi * panorama_height
        
        return u, v
    
    def reconstruct_panorama_with_detections(self, faces_with_detections, panorama_width, panorama_height):
        """
        é‡å»ºå¸¦æœ‰æ£€æµ‹ç»“æœçš„å…¨æ™¯å›¾
        
        Args:
            faces_with_detections: å¸¦æœ‰æ£€æµ‹ç»“æœçš„ç«‹æ–¹ä½“é¢
            panorama_width: å…¨æ™¯å›¾å®½åº¦
            panorama_height: å…¨æ™¯å›¾é«˜åº¦
            
        Returns:
            ndarray: é‡å»ºçš„å…¨æ™¯å›¾
        """
        print("ğŸ”„ é‡å»ºå¸¦æ£€æµ‹ç»“æœçš„å…¨æ™¯å›¾...")
        
        panorama = np.zeros((panorama_height, panorama_width, 3), dtype=np.uint8)
        
        # è·å–ç«‹æ–¹ä½“é¢å°ºå¯¸
        cube_size = self.config['cube_size']
        if cube_size is None:
            first_face = list(faces_with_detections.values())[0]
            cube_size = first_face.shape[0]
        
        print(f"ğŸ“ é‡å»ºä½¿ç”¨ç«‹æ–¹ä½“é¢å°ºå¯¸: {cube_size}")
        
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„é‡å»ºç®—æ³•ï¼Œç¡®ä¿æ²¡æœ‰é»‘è‰²åŒºåŸŸ
        self._reconstruct_panorama_improved(panorama, faces_with_detections, panorama_width, panorama_height, cube_size)
        
        print("âœ… å…¨æ™¯å›¾é‡å»ºå®Œæˆ")
        return panorama
    
    def _reconstruct_panorama_improved(self, panorama, faces_with_detections, panorama_width, panorama_height, cube_size):
        """æ”¹è¿›çš„å…¨æ™¯å›¾é‡å»ºç®—æ³•ï¼Œæ¶ˆé™¤é»‘è‰²åŒºåŸŸ"""
        
        print(f"ğŸ” CUDAçŠ¶æ€æ£€æŸ¥: use_cuda={self.use_cuda}, CUDA_AVAILABLE={CUDA_AVAILABLE}")
        if self.use_cuda and CUDA_AVAILABLE:
            print("ğŸš€ ä½¿ç”¨CUDAåŠ é€Ÿé‡å»ºå…¨æ™¯å›¾...")
            self._reconstruct_panorama_cuda(panorama, faces_with_detections, panorama_width, panorama_height, cube_size)
        else:
            print("ğŸ’» ä½¿ç”¨CPUé‡å»ºå…¨æ™¯å›¾...")
            self._reconstruct_panorama_cpu(panorama, faces_with_detections, panorama_width, panorama_height, cube_size)
    
    def _reconstruct_panorama_cuda(self, panorama, faces_with_detections, panorama_width, panorama_height, cube_size):
        """CUDAåŠ é€Ÿçš„å…¨æ™¯å›¾é‡å»º"""
        print("ğŸš€ å¯åŠ¨CUDAé‡å»ºæ¨¡å¼...")
        
        try:
            # å°†ç«‹æ–¹ä½“é¢ä¼ è¾“åˆ°GPU
            faces_gpu = {}
            for face_name, face_img in faces_with_detections.items():
                faces_gpu[face_name] = cp.asarray(face_img)
            print(f"âœ… {len(faces_gpu)} ä¸ªç«‹æ–¹ä½“é¢å·²ä¼ è¾“åˆ°GPU")
            
            # ä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡ä»¥é¿å…å†…å­˜é—®é¢˜
            batch_size = 128  # å‡å°æ‰¹æ¬¡å¤§å°
            total_batches = (panorama_height + batch_size - 1) // batch_size
            
            print(f"ğŸ“Š CUDAåˆ†æ‰¹å¤„ç†: {total_batches} æ‰¹æ¬¡ï¼Œæ¯æ‰¹ {batch_size} è¡Œ")
            
            for batch_idx in tqdm(range(total_batches), desc="ğŸš€ CUDAé‡å»ºå…¨æ™¯å›¾"):
                start_row = batch_idx * batch_size
                end_row = min(start_row + batch_size, panorama_height)
                current_height = end_row - start_row
                
                # ä¸ºå½“å‰æ‰¹æ¬¡åˆ›å»ºåæ ‡ç½‘æ ¼
                v_coords, u_coords = cp.meshgrid(
                    cp.arange(start_row, end_row),
                    cp.arange(panorama_width),
                    indexing='ij'
                )
                
                # æ‰¹é‡è®¡ç®—çƒé¢åæ ‡
                theta = (u_coords / panorama_width) * 2 * cp.pi - cp.pi
                phi = (v_coords / panorama_height) * cp.pi
                
                # æ‰¹é‡è®¡ç®—3Dåæ ‡
                x = cp.sin(phi) * cp.sin(theta)
                y = cp.cos(phi)
                z = cp.sin(phi) * cp.cos(theta)
                
                # æ‰¹é‡å¤„ç†å½“å‰æ‰¹æ¬¡
                batch_panorama = self._process_batch_cuda_simple(x, y, z, faces_gpu, cube_size)
                
                # ä¼ è¾“å›CPU
                panorama[start_row:end_row, :, :] = cp.asnumpy(batch_panorama)
                
                # æ¸…ç†GPUå†…å­˜
                del v_coords, u_coords, theta, phi, x, y, z, batch_panorama
                cp.get_default_memory_pool().free_all_blocks()
            
            # æ¸…ç†GPUç«‹æ–¹ä½“é¢
            for face_name in list(faces_gpu.keys()):
                del faces_gpu[face_name]
            cp.get_default_memory_pool().free_all_blocks()
            
            print("âœ… CUDAé‡å»ºå®Œæˆ")
            
        except Exception as e:
            print(f"âŒ CUDAé‡å»ºå¤±è´¥: {e}")
            print("ğŸ”„ å›é€€åˆ°CPUé‡å»º...")
            self._reconstruct_panorama_cpu(panorama, faces_with_detections, panorama_width, panorama_height, cube_size)
    
    def _process_batch_cuda(self, batch_x, batch_y, batch_z, faces_gpu, cube_size):
        """CUDAæ‰¹é‡å¤„ç†"""
        batch_h, batch_w = batch_x.shape
        batch_panorama = cp.zeros((batch_h, batch_w, 3), dtype=cp.uint8)
        
        # è®¡ç®—æ¯ä¸ªé¢çš„æ˜ å°„
        face_mappings = self._compute_face_mappings_cuda(batch_x, batch_y, batch_z, cube_size)
        
        # ä¸ºæ¯ä¸ªé¢åº”ç”¨æ˜ å°„
        for face_name, (face_mask, face_u, face_v) in face_mappings.items():
            if face_name in faces_gpu and cp.any(face_mask):
                face_img = faces_gpu[face_name]
                face_h, face_w = face_img.shape[:2]
                
                # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                face_u = cp.clip(face_u, 0, face_w - 1)
                face_v = cp.clip(face_v, 0, face_h - 1)
                
                # åŒçº¿æ€§æ’å€¼
                sampled_pixels = self._cuda_bilinear_sample_3d(face_img, face_u, face_v, face_mask)
                batch_panorama[face_mask] = sampled_pixels
        
        return batch_panorama
    
    def _compute_face_mappings_cuda(self, x, y, z, cube_size):
        """CUDAè®¡ç®—é¢æ˜ å°„"""
        abs_x, abs_y, abs_z = cp.abs(x), cp.abs(y), cp.abs(z)
        
        face_mappings = {}
        
        # Front face (z > 0 and abs_z >= abs_x and abs_z >= abs_y)
        front_mask = (z > 0) & (abs_z >= abs_x) & (abs_z >= abs_y)
        if cp.any(front_mask):
            face_u = (x[front_mask] / z[front_mask] + 1) * 0.5 * cube_size
            face_v = (-y[front_mask] / z[front_mask] + 1) * 0.5 * cube_size
            face_mappings['front'] = (front_mask, face_u, face_v)
        
        # Back face (z < 0 and abs_z >= abs_x and abs_z >= abs_y)
        back_mask = (z < 0) & (abs_z >= abs_x) & (abs_z >= abs_y)
        if cp.any(back_mask):
            face_u = (-x[back_mask] / (-z[back_mask]) + 1) * 0.5 * cube_size
            face_v = (-y[back_mask] / (-z[back_mask]) + 1) * 0.5 * cube_size
            face_mappings['back'] = (back_mask, face_u, face_v)
        
        # Right face (x > 0 and abs_x >= abs_y and abs_x >= abs_z)
        right_mask = (x > 0) & (abs_x >= abs_y) & (abs_x >= abs_z)
        if cp.any(right_mask):
            face_u = (-z[right_mask] / x[right_mask] + 1) * 0.5 * cube_size
            face_v = (-y[right_mask] / x[right_mask] + 1) * 0.5 * cube_size
            face_mappings['right'] = (right_mask, face_u, face_v)
        
        # Left face (x < 0 and abs_x >= abs_y and abs_x >= abs_z)
        left_mask = (x < 0) & (abs_x >= abs_y) & (abs_x >= abs_z)
        if cp.any(left_mask):
            face_u = (z[left_mask] / (-x[left_mask]) + 1) * 0.5 * cube_size
            face_v = (-y[left_mask] / (-x[left_mask]) + 1) * 0.5 * cube_size
            face_mappings['left'] = (left_mask, face_u, face_v)
        
        # Top face (y > 0 and abs_y >= abs_x and abs_y >= abs_z)
        top_mask = (y > 0) & (abs_y >= abs_x) & (abs_y >= abs_z)
        if cp.any(top_mask):
            face_u = (x[top_mask] / y[top_mask] + 1) * 0.5 * cube_size
            face_v = (z[top_mask] / y[top_mask] + 1) * 0.5 * cube_size
            face_mappings['top'] = (top_mask, face_u, face_v)
        
        # Bottom face (y < 0 and abs_y >= abs_x and abs_y >= abs_z)
        bottom_mask = (y < 0) & (abs_y >= abs_x) & (abs_y >= abs_z)
        if cp.any(bottom_mask):
            face_u = (x[bottom_mask] / (-y[bottom_mask]) + 1) * 0.5 * cube_size
            face_v = (z[bottom_mask] / (-y[bottom_mask]) + 1) * 0.5 * cube_size
            face_mappings['bottom'] = (bottom_mask, face_u, face_v)
        
        return face_mappings
    
    def _cuda_bilinear_sample_3d(self, img_gpu, u, v, mask):
        """CUDAä¸‰ç»´åŒçº¿æ€§æ’å€¼é‡‡æ ·"""
        h, w = img_gpu.shape[:2]
        
        # è·å–æ•´æ•°åæ ‡
        u_int = cp.floor(u).astype(cp.int32)
        v_int = cp.floor(v).astype(cp.int32)
        u_frac = u - u_int
        v_frac = v - v_int
        
        # è¾¹ç•Œæ£€æŸ¥
        u_int = cp.clip(u_int, 0, w - 2)
        v_int = cp.clip(v_int, 0, h - 2)
        
        # è·å–å››ä¸ªé‚»è¿‘åƒç´ 
        pixels = cp.zeros((len(u), 3), dtype=cp.uint8)
        
        for c in range(3):
            p00 = img_gpu[v_int, u_int, c]
            p01 = img_gpu[v_int, u_int + 1, c]
            p10 = img_gpu[v_int + 1, u_int, c]
            p11 = img_gpu[v_int + 1, u_int + 1, c]
            
            # åŒçº¿æ€§æ’å€¼
            interpolated = (p00 * (1 - u_frac) * (1 - v_frac) +
                          p01 * u_frac * (1 - v_frac) +
                          p10 * (1 - u_frac) * v_frac +
                          p11 * u_frac * v_frac)
            
            pixels[:, c] = interpolated.astype(cp.uint8)
        
        return pixels
    
    def _process_batch_cuda_simple(self, x, y, z, faces_gpu, cube_size):
        """ç®€åŒ–çš„CUDAæ‰¹å¤„ç†"""
        batch_h, batch_w = x.shape
        batch_panorama = cp.zeros((batch_h, batch_w, 3), dtype=cp.uint8)
        
        # è®¡ç®—ç»å¯¹å€¼
        abs_x, abs_y, abs_z = cp.abs(x), cp.abs(y), cp.abs(z)
        
        # å¤„ç†æ¯ä¸ªé¢
        for face_name, face_img in faces_gpu.items():
            face_h, face_w = face_img.shape[:2]
            
            # ç¡®å®šå½“å‰é¢çš„æ©ç å’Œåæ ‡
            if face_name == 'front':
                mask = (z > 0) & (abs_z >= abs_x) & (abs_z >= abs_y)
                if cp.any(mask):
                    face_u = (x[mask] / z[mask] + 1) * 0.5 * cube_size
                    face_v = (-y[mask] / z[mask] + 1) * 0.5 * cube_size
            elif face_name == 'back':
                mask = (z < 0) & (abs_z >= abs_x) & (abs_z >= abs_y)
                if cp.any(mask):
                    face_u = (-x[mask] / (-z[mask]) + 1) * 0.5 * cube_size
                    face_v = (-y[mask] / (-z[mask]) + 1) * 0.5 * cube_size
            elif face_name == 'right':
                mask = (x > 0) & (abs_x >= abs_y) & (abs_x >= abs_z)
                if cp.any(mask):
                    face_u = (-z[mask] / x[mask] + 1) * 0.5 * cube_size
                    face_v = (-y[mask] / x[mask] + 1) * 0.5 * cube_size
            elif face_name == 'left':
                mask = (x < 0) & (abs_x >= abs_y) & (abs_x >= abs_z)
                if cp.any(mask):
                    face_u = (z[mask] / (-x[mask]) + 1) * 0.5 * cube_size
                    face_v = (-y[mask] / (-x[mask]) + 1) * 0.5 * cube_size
            elif face_name == 'top':
                mask = (y > 0) & (abs_y >= abs_x) & (abs_y >= abs_z)
                if cp.any(mask):
                    face_u = (x[mask] / y[mask] + 1) * 0.5 * cube_size
                    face_v = (z[mask] / y[mask] + 1) * 0.5 * cube_size
            elif face_name == 'bottom':
                mask = (y < 0) & (abs_y >= abs_x) & (abs_y >= abs_z)
                if cp.any(mask):
                    face_u = (x[mask] / (-y[mask]) + 1) * 0.5 * cube_size
                    face_v = (z[mask] / (-y[mask]) + 1) * 0.5 * cube_size
            else:
                continue
            
            if cp.any(mask):
                # è¾¹ç•Œæ£€æŸ¥
                face_u = cp.clip(face_u, 0, face_w - 1)
                face_v = cp.clip(face_v, 0, face_h - 1)
                
                # ç®€å•çš„æœ€è¿‘é‚»æ’å€¼
                u_int = cp.round(face_u).astype(cp.int32)
                v_int = cp.round(face_v).astype(cp.int32)
                
                # é‡‡æ ·åƒç´ 
                sampled_pixels = face_img[v_int, u_int]
                batch_panorama[mask] = sampled_pixels
        
        return batch_panorama
    
    def _reconstruct_panorama_cpu(self, panorama, faces_with_detections, panorama_width, panorama_height, cube_size):
        """CPUç‰ˆæœ¬çš„å…¨æ™¯å›¾é‡å»º"""
        print("ğŸ’» CPUé‡å»ºæ¨¡å¼ - é¢„è®¡ç®—åæ ‡æ˜ å°„...")
        
        for v in tqdm(range(panorama_height), desc="CPUé‡å»ºå…¨æ™¯å›¾è¡Œ"):
            for u in range(panorama_width):
                # å…¨æ™¯å›¾åæ ‡è½¬æ¢ä¸ºçƒé¢åæ ‡
                theta = (u / panorama_width) * 2 * math.pi - math.pi
                phi = (v / panorama_height) * math.pi
                
                # çƒé¢åæ ‡è½¬æ¢ä¸º3Dåæ ‡
                x = math.sin(phi) * math.sin(theta)
                y = math.cos(phi)
                z = math.sin(phi) * math.cos(theta)
                
                # ç¡®å®šå±äºå“ªä¸ªç«‹æ–¹ä½“é¢å¹¶è·å–ç²¾ç¡®åæ ‡
                face_name, face_u, face_v = self._xyz_to_cube_face_precise(x, y, z, cube_size)
                
                if face_name and face_name in faces_with_detections:
                    face_img = faces_with_detections[face_name]
                    face_h, face_w = face_img.shape[:2]
                    
                    # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                    face_u = max(0, min(face_w - 1, face_u))
                    face_v = max(0, min(face_h - 1, face_v))
                    
                    # ä½¿ç”¨åŒçº¿æ€§æ’å€¼è·å–æ›´å¹³æ»‘çš„ç»“æœ
                    pixel_value = self._bilinear_interpolation(face_img, face_u, face_v)
                    panorama[v, u] = pixel_value
    
    def _xyz_to_cube_face_precise(self, x, y, z, cube_size):
        """ç²¾ç¡®çš„3Dåæ ‡åˆ°ç«‹æ–¹ä½“é¢æ˜ å°„"""
        abs_x, abs_y, abs_z = abs(x), abs(y), abs(z)
        
        # æ‰¾åˆ°æœ€å¤§çš„åˆ†é‡æ¥ç¡®å®šé¢
        if abs_z >= abs_x and abs_z >= abs_y:
            if z > 0:  # front
                face_name = 'front'
                face_u = (x / z + 1) * 0.5 * cube_size
                face_v = (-y / z + 1) * 0.5 * cube_size
            else:  # back
                face_name = 'back'
                face_u = (-x / (-z) + 1) * 0.5 * cube_size
                face_v = (-y / (-z) + 1) * 0.5 * cube_size
        elif abs_x >= abs_y:
            if x > 0:  # right
                face_name = 'right'
                face_u = (-z / x + 1) * 0.5 * cube_size
                face_v = (-y / x + 1) * 0.5 * cube_size
            else:  # left
                face_name = 'left'
                face_u = (z / (-x) + 1) * 0.5 * cube_size
                face_v = (-y / (-x) + 1) * 0.5 * cube_size
        else:
            if y > 0:  # top
                face_name = 'top'
                face_u = (x / y + 1) * 0.5 * cube_size
                face_v = (z / y + 1) * 0.5 * cube_size
            else:  # bottom
                face_name = 'bottom'
                face_u = (x / (-y) + 1) * 0.5 * cube_size
                face_v = (z / (-y) + 1) * 0.5 * cube_size
        
        return face_name, face_u, face_v
    
    def _bilinear_interpolation(self, img, x, y):
        """åŒçº¿æ€§æ’å€¼è·å–åƒç´ å€¼"""
        h, w = img.shape[:2]
        
        # è·å–æ•´æ•°åæ ‡
        x1, y1 = int(x), int(y)
        x2, y2 = min(x1 + 1, w - 1), min(y1 + 1, h - 1)
        
        # è®¡ç®—æƒé‡
        wx = x - x1
        wy = y - y1
        
        # åŒçº¿æ€§æ’å€¼
        if len(img.shape) == 3:  # å½©è‰²å›¾åƒ
            pixel = (1 - wy) * ((1 - wx) * img[y1, x1] + wx * img[y1, x2]) + \
                    wy * ((1 - wx) * img[y2, x1] + wx * img[y2, x2])
        else:  # ç°åº¦å›¾åƒ
            pixel = (1 - wy) * ((1 - wx) * img[y1, x1] + wx * img[y1, x2]) + \
                    wy * ((1 - wx) * img[y2, x1] + wx * img[y2, x2])
        
        return pixel.astype(np.uint8)
    
    def _save_feature_images(self, img1, img2, kp1, kp2, output_dir, face_name):
        """ä¿å­˜ç‰¹å¾ç‚¹å›¾åƒ"""
        # ç»˜åˆ¶ç¬¬ä¸€å¼ å›¾çš„ç‰¹å¾ç‚¹
        img1_kp = cv2.drawKeypoints(img1, kp1, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
        cv2.imwrite(os.path.join(output_dir, f"03_{face_name}_features_face1.jpg"), img1_kp)
        
        # ç»˜åˆ¶ç¬¬äºŒå¼ å›¾çš„ç‰¹å¾ç‚¹
        img2_kp = cv2.drawKeypoints(img2, kp2, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
        cv2.imwrite(os.path.join(output_dir, f"03_{face_name}_features_face2.jpg"), img2_kp)
    
    def _save_feature_matching_image(self, img1, img2, kp1, kp2, des1, des2, output_dir, face_name):
        """ä¿å­˜ç‰¹å¾åŒ¹é…å›¾åƒ"""
        if des1 is None or des2 is None or len(kp1) < 4 or len(kp2) < 4:
            # å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾ç‚¹ï¼Œåˆ›å»ºç©ºç™½åŒ¹é…å›¾
            h1, w1 = img1.shape[:2]
            h2, w2 = img2.shape[:2]
            match_img = np.zeros((max(h1, h2), w1 + w2, 3), dtype=np.uint8)
            match_img[:h1, :w1] = img1
            match_img[:h2, w1:w1+w2] = img2
            cv2.putText(match_img, "Insufficient features for matching", 
                       (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3)
        else:
            # ä½¿ç”¨BFMatcherè¿›è¡Œç‰¹å¾åŒ¹é…
            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
            matches = bf.match(des1, des2)
            matches = sorted(matches, key=lambda x: x.distance)
            
            # åªæ˜¾ç¤ºå‰50ä¸ªæœ€ä½³åŒ¹é…
            match_img = cv2.drawMatches(img1, kp1, img2, kp2, matches[:50], None, 
                                      flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
        
        cv2.imwrite(os.path.join(output_dir, f"03_{face_name}_feature_matching.jpg"), match_img)
    
    def _save_morphology_steps(self, diff_img, final_binary, output_dir, face_name):
        """ä¿å­˜å½¢æ€å­¦æ“ä½œçš„å„ä¸ªæ­¥éª¤"""
        # 1. ä¿å­˜åŸå§‹é˜ˆå€¼åˆ†å‰²ç»“æœ
        _, binary_thresh = cv2.threshold(diff_img, self.config['diff_threshold'], 255, cv2.THRESH_BINARY)
        cv2.imwrite(os.path.join(output_dir, f"06a_{face_name}_threshold.jpg"), binary_thresh)
        
        # 2. åˆ›å»ºå½¢æ€å­¦æ ¸
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, self.config['morphology_kernel_size'])
        
        # 3. é—­è¿ç®—ï¼ˆå…ˆè†¨èƒ€åè…èš€ï¼‰
        closed = cv2.morphologyEx(binary_thresh, cv2.MORPH_CLOSE, kernel)
        cv2.imwrite(os.path.join(output_dir, f"06b_{face_name}_morphology_close.jpg"), closed)
        
        # 4. å¼€è¿ç®—ï¼ˆå…ˆè…èš€åè†¨èƒ€ï¼‰
        opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel)
        cv2.imwrite(os.path.join(output_dir, f"06c_{face_name}_morphology_open.jpg"), opened)
        
        # 5. ä¿å­˜æœ€ç»ˆäºŒå€¼å›¾
        cv2.imwrite(os.path.join(output_dir, f"06d_{face_name}_final_binary.jpg"), final_binary)
        
        # 6. åˆ›å»ºå½¢æ€å­¦æ“ä½œå¯¹æ¯”å›¾
        self._create_morphology_comparison(binary_thresh, closed, opened, final_binary, output_dir, face_name)
    
    def _create_morphology_comparison(self, thresh, closed, opened, final, output_dir, face_name):
        """åˆ›å»ºå½¢æ€å­¦æ“ä½œå¯¹æ¯”å›¾"""
        # åˆ›å»º2x2ç½‘æ ¼æ˜¾ç¤º
        h, w = thresh.shape
        comparison = np.zeros((2*h, 2*w), dtype=np.uint8)
        
        # å·¦ä¸Šï¼šåŸå§‹é˜ˆå€¼
        comparison[:h, :w] = thresh
        # å³ä¸Šï¼šé—­è¿ç®—
        comparison[:h, w:] = closed
        # å·¦ä¸‹ï¼šå¼€è¿ç®—  
        comparison[h:, :w] = opened
        # å³ä¸‹ï¼šæœ€ç»ˆç»“æœ
        comparison[h:, w:] = final
        
        # æ·»åŠ æ ‡ç­¾
        comparison_color = cv2.cvtColor(comparison, cv2.COLOR_GRAY2BGR)
        cv2.putText(comparison_color, "Threshold", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(comparison_color, "Close", (w+10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(comparison_color, "Open", (10, h+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(comparison_color, "Final", (w+10, h+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        cv2.imwrite(os.path.join(output_dir, f"06e_{face_name}_morphology_comparison.jpg"), comparison_color)
    
    def _xyz_to_cube_face(self, x, y, z, cube_size):
        """ç¡®å®š3Dåæ ‡å±äºå“ªä¸ªç«‹æ–¹ä½“é¢"""
        abs_x, abs_y, abs_z = abs(x), abs(y), abs(z)
        
        if abs_z >= abs_x and abs_z >= abs_y:
            if z > 0:  # front
                face_name = 'front'
                face_u = (x / z + 1) * 0.5 * cube_size
                face_v = (-y / z + 1) * 0.5 * cube_size
            else:  # back
                face_name = 'back'
                face_u = (-x / (-z) + 1) * 0.5 * cube_size
                face_v = (-y / (-z) + 1) * 0.5 * cube_size
        elif abs_x >= abs_y:
            if x > 0:  # right
                face_name = 'right'
                face_u = (-z / x + 1) * 0.5 * cube_size
                face_v = (-y / x + 1) * 0.5 * cube_size
            else:  # left
                face_name = 'left'
                face_u = (z / (-x) + 1) * 0.5 * cube_size
                face_v = (-y / (-x) + 1) * 0.5 * cube_size
        else:
            if y > 0:  # top
                face_name = 'top'
                face_u = (x / y + 1) * 0.5 * cube_size
                face_v = (z / y + 1) * 0.5 * cube_size
            else:  # bottom
                face_name = 'bottom'
                face_u = (x / (-y) + 1) * 0.5 * cube_size
                face_v = (z / (-y) + 1) * 0.5 * cube_size
        
        return face_name, face_u, face_v
    
    def process_face_pair(self, face1, face2, face_name):
        """
        å¤„ç†å•ä¸ªç«‹æ–¹ä½“é¢å¯¹
        
        Args:
            face1, face2: ä¸¤æœŸç«‹æ–¹ä½“é¢å›¾åƒ
            face_name: é¢åç§°
            
        Returns:
            dict: å¤„ç†ç»“æœ
        """
        print(f"ğŸ”„ å¤„ç† {face_name} é¢ ({self.face_descriptions[face_name]})...")
        
        # åˆ›å»ºé¢ä¸“ç”¨çš„è¾“å‡ºç›®å½•
        face_output_dir = os.path.join(self.output_dir, f"face_{face_name}_steps")
        os.makedirs(face_output_dir, exist_ok=True)
        
        # 1. ä¿å­˜åŸå§‹å›¾åƒ
        cv2.imwrite(os.path.join(face_output_dir, f"01_{face_name}_original_face1.jpg"), face1)
        cv2.imwrite(os.path.join(face_output_dir, f"01_{face_name}_original_face2.jpg"), face2)
        
        # 2. å›¾åƒé¢„å¤„ç†
        acceleration = "ğŸš€ CUDA" if self.use_cuda and CUDA_AVAILABLE else "ğŸ’» CPU"
        print(f"   é¢„å¤„ç†åŠ é€Ÿ: {acceleration}")
        processed_face1 = self.preprocess_image(face1)
        processed_face2 = self.preprocess_image(face2)
        
        # ä¿å­˜é¢„å¤„ç†ç»“æœ
        cv2.imwrite(os.path.join(face_output_dir, f"02_{face_name}_preprocessed_face1.jpg"), processed_face1)
        cv2.imwrite(os.path.join(face_output_dir, f"02_{face_name}_preprocessed_face2.jpg"), processed_face2)
        
        # 3. AKAZEç‰¹å¾æå–
        kp1, des1 = self.extract_akaze_features(processed_face1)
        kp2, des2 = self.extract_akaze_features(processed_face2)
        
        print(f"   ç‰¹å¾ç‚¹: {len(kp1)} vs {len(kp2)}")
        
        # ä¿å­˜ç‰¹å¾ç‚¹å›¾åƒ
        self._save_feature_images(processed_face1, processed_face2, kp1, kp2, face_output_dir, face_name)
        
        # 4. ç‰¹å¾åŒ¹é…å’Œé…å‡†
        registered_face2, homography, match_info = self.match_features_and_register(
            processed_face1, processed_face2, kp1, des1, kp2, des2
        )
        
        # ä¿å­˜é…å‡†ç»“æœ
        cv2.imwrite(os.path.join(face_output_dir, f"04_{face_name}_registered_face2.jpg"), registered_face2)
        
        # ä¿å­˜ç‰¹å¾åŒ¹é…å›¾åƒ
        self._save_feature_matching_image(processed_face1, processed_face2, kp1, kp2, des1, des2, face_output_dir, face_name)
        
        # 5. å›¾åƒå·®åˆ†
        print(f"   å·®åˆ†è®¡ç®—: {acceleration}")
        diff_img = self.compute_image_difference(processed_face1, registered_face2)
        
        # ä¿å­˜å·®åˆ†å›¾åƒ
        cv2.imwrite(os.path.join(face_output_dir, f"05_{face_name}_difference.jpg"), diff_img)
        
        # 6. é˜ˆå€¼åˆ†å‰²å’Œå½¢æ€å­¦æ“ä½œ
        print(f"   å½¢æ€å­¦æ“ä½œ: {acceleration}")
        binary_img = self.threshold_and_morphology(diff_img)
        
        # ä¿å­˜äºŒå€¼åŒ–å’Œå½¢æ€å­¦æ“ä½œç»“æœ
        self._save_morphology_steps(diff_img, binary_img, face_output_dir, face_name)
        
        # 7. è½®å»“æå–å’Œè¾¹ç•Œæ¡†ç”Ÿæˆ
        face_bboxes, vis_img = self.extract_contours_and_bboxes(binary_img, registered_face2)
        
        # ä¿å­˜æœ€ç»ˆæ£€æµ‹ç»“æœ
        cv2.imwrite(os.path.join(face_output_dir, f"07_{face_name}_final_detection.jpg"), vis_img)
        
        result = {
            'face_name': face_name,
            'original_face1': face1,
            'original_face2': face2,
            'processed_face1': processed_face1,
            'processed_face2': processed_face2,
            'registered_face2': registered_face2,
            'diff_image': diff_img,
            'binary_image': binary_img,
            'visualization': vis_img,
            'bboxes': face_bboxes,
            'match_info': match_info,
            'feature_points': {
                'face1_kp_count': len(kp1),
                'face2_kp_count': len(kp2),
                'matches': match_info['matches'],
                'inliers': match_info['inliers']
            },
            'step_images_saved': face_output_dir
        }
        
        print(f"âœ… {face_name} é¢å¤„ç†å®Œæˆï¼Œæ£€æµ‹åˆ° {len(face_bboxes)} ä¸ªå˜åŒ–åŒºåŸŸ")
        print(f"ğŸ“ å¤„ç†æ­¥éª¤å›¾åƒå·²ä¿å­˜è‡³: {face_output_dir}")
        
        return result
    
    def create_comprehensive_visualization(self, all_results, panorama1, panorama2, final_panorama, all_panorama_bboxes):
        """
        åˆ›å»ºç»¼åˆå¯è§†åŒ–ç»“æœ
        
        Args:
            all_results: æ‰€æœ‰ç«‹æ–¹ä½“é¢çš„å¤„ç†ç»“æœ
            panorama1: ç¬¬ä¸€æœŸå…¨æ™¯å›¾
            panorama2: ç¬¬äºŒæœŸå…¨æ™¯å›¾
            final_panorama: æœ€ç»ˆé‡å»ºçš„å…¨æ™¯å›¾
            all_panorama_bboxes: æ‰€æœ‰å…¨æ™¯å›¾è¾¹ç•Œæ¡†
            
        Returns:
            str: ä¿å­˜çš„å¯è§†åŒ–å›¾åƒè·¯å¾„
        """
        print("ğŸ¨ åˆ›å»ºç»¼åˆå¯è§†åŒ–...")
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # åˆ›å»ºå¤§å‹å›¾å½¢
        fig = plt.figure(figsize=(24, 18))
        
        # ä¸»æ ‡é¢˜
        fig.suptitle('å…¨æ™¯å›¾åƒå˜åŒ–æ£€æµ‹ç³»ç»Ÿ - ç»¼åˆåˆ†æç»“æœ', fontsize=20, fontweight='bold', y=0.98)
        
        # åˆ›å»ºç½‘æ ¼å¸ƒå±€
        gs = fig.add_gridspec(4, 6, height_ratios=[1, 1, 1, 0.8], hspace=0.3, wspace=0.3)
        
        # ç¬¬ä¸€è¡Œï¼šå…¨æ™¯å›¾å¯¹æ¯”
        ax1 = fig.add_subplot(gs[0, :2])
        ax1.imshow(cv2.cvtColor(panorama1, cv2.COLOR_BGR2RGB))
        ax1.set_title('ç¬¬ä¸€æœŸå…¨æ™¯å›¾ï¼ˆåŸºå‡†ï¼‰', fontsize=14, fontweight='bold')
        ax1.axis('off')
        
        ax2 = fig.add_subplot(gs[0, 2:4])
        ax2.imshow(cv2.cvtColor(panorama2, cv2.COLOR_BGR2RGB))
        ax2.set_title('ç¬¬äºŒæœŸå…¨æ™¯å›¾ï¼ˆå¾…æ£€æµ‹ï¼‰', fontsize=14, fontweight='bold')
        ax2.axis('off')
        
        # å¸¦æ£€æµ‹ç»“æœçš„å…¨æ™¯å›¾
        panorama_with_detections = final_panorama.copy()
        colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]
        
        for i, bbox_info in enumerate(all_panorama_bboxes):
            if 'panorama_bbox' in bbox_info:
                x, y, w, h = bbox_info['panorama_bbox']
                color = colors[i % len(colors)]
                cv2.rectangle(panorama_with_detections, (x, y), (x+w, y+h), color, 3)
                cv2.putText(panorama_with_detections, f"å˜åŒ–{i+1}", 
                           (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        
        ax3 = fig.add_subplot(gs[0, 4:])
        ax3.imshow(cv2.cvtColor(panorama_with_detections, cv2.COLOR_BGR2RGB))
        ax3.set_title(f'æ£€æµ‹ç»“æœå…¨æ™¯å›¾ (å‘ç° {len(all_panorama_bboxes)} ä¸ªå˜åŒ–åŒºåŸŸ)', fontsize=14, fontweight='bold')
        ax3.axis('off')
        
        # ç¬¬äºŒè¡Œå’Œç¬¬ä¸‰è¡Œï¼šæ¯ä¸ªç«‹æ–¹ä½“é¢çš„è¯¦ç»†ç»“æœ
        valid_results = [r for r in all_results if len(r['bboxes']) > 0]
        
        row_idx = 1
        col_idx = 0
        for result in valid_results[:6]:  # æœ€å¤šæ˜¾ç¤º6ä¸ªæœ‰æ£€æµ‹ç»“æœçš„é¢
            if row_idx >= 3:
                break
                
            ax = fig.add_subplot(gs[row_idx, col_idx])
            ax.imshow(cv2.cvtColor(result['visualization'], cv2.COLOR_BGR2RGB))
            ax.set_title(f"{result['face_name']} é¢\næ£€æµ‹: {len(result['bboxes'])}ä¸ª", 
                        fontsize=12, fontweight='bold')
            ax.axis('off')
            
            col_idx += 1
            if col_idx >= 6:
                col_idx = 0
                row_idx += 1
        
        # ç¬¬å››è¡Œï¼šç»Ÿè®¡ä¿¡æ¯
        # æ€»ä½“ç»Ÿè®¡
        total_faces_processed = len(all_results)
        total_detections = sum(len(r['bboxes']) for r in all_results)
        faces_with_changes = len([r for r in all_results if len(r['bboxes']) > 0])
        
        ax_stats1 = fig.add_subplot(gs[3, :2])
        stats_text = f"""ğŸ“Š æ£€æµ‹ç»Ÿè®¡æ‘˜è¦
        
æ€»å¤„ç†é¢æ•°: {total_faces_processed} / {len(self.face_names)}
å‘ç°å˜åŒ–çš„é¢: {faces_with_changes}
æ€»å˜åŒ–åŒºåŸŸæ•°: {total_detections}
å…¨æ™¯å›¾æ£€æµ‹æ¡†: {len(all_panorama_bboxes)}

ç³»ç»Ÿé…ç½®:
â€¢ ç«‹æ–¹ä½“å°ºå¯¸: {self.config['cube_size']}Ã—{self.config['cube_size']} (åŠ¨æ€)
â€¢ å·®å¼‚é˜ˆå€¼: {self.config['diff_threshold']}
â€¢ æœ€å°åŒºåŸŸé¢ç§¯: {self.config['min_contour_area']} pxÂ²
â€¢ è·³è¿‡é¢: {', '.join(self.config['skip_faces'])}
â€¢ ä½¿ç”¨GPUåŠ é€Ÿ: {'æ˜¯' if self.use_cuda else 'å¦'}
"""
        
        ax_stats1.text(0.05, 0.95, stats_text, transform=ax_stats1.transAxes, fontsize=11,
                      verticalalignment='top', bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))
        ax_stats1.set_xlim(0, 1)
        ax_stats1.set_ylim(0, 1)
        ax_stats1.axis('off')
        ax_stats1.set_title('ç³»ç»Ÿç»Ÿè®¡', fontsize=12, fontweight='bold')
        
        # é¢è¯¦ç»†ä¿¡æ¯
        ax_stats2 = fig.add_subplot(gs[3, 2:4])
        face_details = "ğŸ” å„é¢æ£€æµ‹è¯¦æƒ…\n\n"
        
        # æ˜¾ç¤ºå¤„ç†çš„é¢
        for result in all_results:
            status = f"âœ… {len(result['bboxes'])}ä¸ª" if len(result['bboxes']) > 0 else "â­• æ— å˜åŒ–"
            face_details += f"{result['face_name']} ({self.face_descriptions[result['face_name']]}): {status}\n"
            if len(result['bboxes']) > 0:
                face_details += f"  ç‰¹å¾åŒ¹é…: {result['match_info']['matches']}ä¸ª\n"
                face_details += f"  å†…ç‚¹æ¯”ä¾‹: {result['match_info']['inlier_ratio']:.2%}\n"
        
        # æ˜¾ç¤ºè·³è¿‡çš„é¢
        for face_name in self.config['skip_faces']:
            face_details += f"{face_name} ({self.face_descriptions[face_name]}): â­ï¸ å·²è·³è¿‡\n"
        
        ax_stats2.text(0.05, 0.95, face_details, transform=ax_stats2.transAxes, fontsize=10,
                      verticalalignment='top', bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', alpha=0.8))
        ax_stats2.set_xlim(0, 1)
        ax_stats2.set_ylim(0, 1)
        ax_stats2.axis('off')
        ax_stats2.set_title('é¢å¤„ç†è¯¦æƒ…', fontsize=12, fontweight='bold')
        
        # æŠ€æœ¯æµç¨‹è¯´æ˜
        ax_tech = fig.add_subplot(gs[3, 4:])
        tech_text = """ğŸ”¬ æŠ€æœ¯å¤„ç†æµç¨‹
        
1ï¸âƒ£ å…¨æ™¯å›¾ç«‹æ–¹ä½“åˆ†å‰²
   â€¢ 6ä¸ªç«‹æ–¹ä½“é¢æå–
   â€¢ GPU/CPUè‡ªé€‚åº”å¤„ç†

2ï¸âƒ£ å›¾åƒé¢„å¤„ç†
   â€¢ é«˜æ–¯æ¨¡ç³Šå»å™ª
   â€¢ CLAHEç›´æ–¹å›¾å‡è¡¡åŒ–

3ï¸âƒ£ ç‰¹å¾æå–ä¸é…å‡†
   â€¢ AKAZEç‰¹å¾ç‚¹æ£€æµ‹
   â€¢ BFåŒ¹é…å™¨ç‰¹å¾åŒ¹é…
   â€¢ RANSACå•åº”æ€§å˜æ¢

4ï¸âƒ£ å˜åŒ–æ£€æµ‹
   â€¢ å›¾åƒå·®åˆ†è®¡ç®—
   â€¢ è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰²
   â€¢ å½¢æ€å­¦æ“ä½œä¼˜åŒ–

5ï¸âƒ£ ç›®æ ‡è¯†åˆ«
   â€¢ è½®å»“æå–åˆ†æ
   â€¢ å‡ ä½•ç‰¹å¾è¿‡æ»¤
   â€¢ ç½®ä¿¡åº¦è¯„ä¼°

6ï¸âƒ£ ç»“æœæ˜ å°„
   â€¢ åæ ‡ç³»é€†å˜æ¢
   â€¢ å…¨æ™¯å›¾é‡å»º
   â€¢ æ£€æµ‹æ¡†å¯è§†åŒ–
"""
        
        ax_tech.text(0.05, 0.95, tech_text, transform=ax_tech.transAxes, fontsize=9,
                    verticalalignment='top', bbox=dict(boxstyle='round,pad=0.5', facecolor='lightyellow', alpha=0.8))
        ax_tech.set_xlim(0, 1)
        ax_tech.set_ylim(0, 1)
        ax_tech.axis('off')
        ax_tech.set_title('æŠ€æœ¯æµç¨‹', fontsize=12, fontweight='bold')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        image_path = os.path.join(self.output_dir, f"panorama_change_detection_comprehensive_{timestamp}.jpg")
        plt.savefig(image_path, dpi=200, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"âœ… ç»¼åˆå¯è§†åŒ–å·²ä¿å­˜: {image_path}")
        return image_path
    
    def save_results(self, all_results, all_panorama_bboxes):
        """
        ä¿å­˜æ£€æµ‹ç»“æœ
        
        Args:
            all_results: æ‰€æœ‰å¤„ç†ç»“æœ
            all_panorama_bboxes: å…¨æ™¯å›¾è¾¹ç•Œæ¡†
            
        Returns:
            str: ä¿å­˜çš„JSONæ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å‡†å¤‡å¯åºåˆ—åŒ–çš„ç»“æœ
        serializable_results = []
        for result in all_results:
            serializable_result = {
                'face_name': result['face_name'],
                'bboxes': result['bboxes'],
                'match_info': result['match_info'],
                'feature_points': result['feature_points'],
                'detection_count': len(result['bboxes'])
            }
            serializable_results.append(serializable_result)
        
        # åˆ›å»ºå®Œæ•´ç»“æœ
        final_results = {
            'timestamp': timestamp,
            'system_config': self.config,
            'processing_summary': {
                'total_faces_processed': len(all_results),
                'faces_with_detections': len([r for r in all_results if len(r['bboxes']) > 0]),
                'total_detections': sum(len(r['bboxes']) for r in all_results),
                'panorama_bboxes_count': len(all_panorama_bboxes),
                'gpu_acceleration_used': self.use_cuda
            },
            'face_results': serializable_results,
            'panorama_bboxes': all_panorama_bboxes
        }
        
        # ä¿å­˜JSONç»“æœ
        json_path = os.path.join(self.output_dir, f"detection_results_{timestamp}.json")
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… æ£€æµ‹ç»“æœå·²ä¿å­˜: {json_path}")
        return json_path
    
    def process_panorama_pair(self, panorama1_path, panorama2_path):
        """
        å¤„ç†å…¨æ™¯å›¾å¯¹çš„å®Œæ•´æµç¨‹
        
        Args:
            panorama1_path (str): ç¬¬ä¸€æœŸå…¨æ™¯å›¾è·¯å¾„
            panorama2_path (str): ç¬¬äºŒæœŸå…¨æ™¯å›¾è·¯å¾„
            
        Returns:
            dict: å®Œæ•´çš„å¤„ç†ç»“æœ
        """
        print("ğŸš€ å¼€å§‹å…¨æ™¯å›¾åƒå˜åŒ–æ£€æµ‹ç³»ç»Ÿå¤„ç†...")
        print(f"ğŸ“‚ ç¬¬ä¸€æœŸå›¾åƒ: {os.path.basename(panorama1_path)}")
        print(f"ğŸ“‚ ç¬¬äºŒæœŸå›¾åƒ: {os.path.basename(panorama2_path)}")
        
        # 1. åŠ è½½å…¨æ™¯å›¾
        print("\nğŸ“– Step 1: åŠ è½½å…¨æ™¯å›¾åƒ...")
        panorama1 = self.load_image_with_chinese_path(panorama1_path)
        panorama2 = self.load_image_with_chinese_path(panorama2_path)
        
        if panorama1 is None or panorama2 is None:
            print("âŒ å›¾åƒåŠ è½½å¤±è´¥")
            return None
        
        print(f"   ç¬¬ä¸€æœŸå°ºå¯¸: {panorama1.shape}")
        print(f"   ç¬¬äºŒæœŸå°ºå¯¸: {panorama2.shape}")
        
        # 2. ç«‹æ–¹ä½“åˆ†å‰²
        print("\nğŸ”„ Step 2: å…¨æ™¯å›¾ç«‹æ–¹ä½“åˆ†å‰²...")
        faces1 = self.panorama_to_cubemap(panorama1)
        faces2 = self.panorama_to_cubemap(panorama2)
        
        # 3. å¤„ç†æ¯ä¸ªç«‹æ–¹ä½“é¢å¯¹
        print("\nğŸ” Step 3: å¤„ç†å„ç«‹æ–¹ä½“é¢...")
        all_results = []
        faces_with_detections = {}
        
        for face_name in self.face_names:
            # è·³è¿‡æŒ‡å®šçš„é¢ï¼ˆå¦‚topé¢ï¼‰
            if face_name in self.config['skip_faces']:
                print(f"â­ï¸ è·³è¿‡ {face_name} é¢ ({self.face_descriptions[face_name]})")
                # ä¸ºè·³è¿‡çš„é¢ä½¿ç”¨åŸå§‹å›¾åƒ
                faces_with_detections[face_name] = faces2[face_name] if face_name in faces2 else faces1[face_name]
                continue
                
            if face_name in faces1 and face_name in faces2:
                face_result = self.process_face_pair(faces1[face_name], faces2[face_name], face_name)
                all_results.append(face_result)
                
                # ä¿å­˜å¸¦æœ‰æ£€æµ‹ç»“æœçš„é¢å›¾åƒ
                faces_with_detections[face_name] = face_result['visualization']
        
        # 4. æ˜ å°„è¾¹ç•Œæ¡†åˆ°å…¨æ™¯å›¾
        print("\nğŸ—ºï¸ Step 4: æ˜ å°„æ£€æµ‹ç»“æœåˆ°å…¨æ™¯å›¾...")
        all_panorama_bboxes = []
        panorama_height, panorama_width = panorama1.shape[:2]
        
        for result in all_results:
            if result['bboxes']:
                face_panorama_bboxes = self.map_bboxes_to_panorama(
                    result['bboxes'], 
                    result['face_name'],
                    self.config['cube_size'],
                    panorama_width,
                    panorama_height
                )
                all_panorama_bboxes.extend(face_panorama_bboxes)
        
        print(f"   æ˜ å°„äº† {len(all_panorama_bboxes)} ä¸ªæ£€æµ‹æ¡†åˆ°å…¨æ™¯å›¾")
        
        # 5. é‡å»ºå…¨æ™¯å›¾
        print("\nğŸ”„ Step 5: é‡å»ºå¸¦æ£€æµ‹ç»“æœçš„å…¨æ™¯å›¾...")
        final_panorama = self.reconstruct_panorama_with_detections(
            faces_with_detections, panorama_width, panorama_height
        )
        
        # 6. åˆ›å»ºå¯è§†åŒ–
        print("\nğŸ¨ Step 6: åˆ›å»ºç»¼åˆå¯è§†åŒ–...")
        visualization_path = self.create_comprehensive_visualization(
            all_results, panorama1, panorama2, final_panorama, all_panorama_bboxes
        )
        
        # 7. ä¿å­˜ç»“æœ
        print("\nğŸ’¾ Step 7: ä¿å­˜æ£€æµ‹ç»“æœ...")
        results_path = self.save_results(all_results, all_panorama_bboxes)
        
        # ä¿å­˜é‡å»ºçš„å…¨æ™¯å›¾
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        final_panorama_path = os.path.join(self.output_dir, f"final_panorama_with_detections_{timestamp}.jpg")
        cv2.imwrite(final_panorama_path, final_panorama)
        
        # æ±‡æ€»ç»“æœ
        summary = {
            'processing_successful': True,
            'total_faces_processed': len(all_results),
            'faces_with_detections': len([r for r in all_results if len(r['bboxes']) > 0]),
            'total_detection_count': sum(len(r['bboxes']) for r in all_results),
            'panorama_bboxes_count': len(all_panorama_bboxes),
            'output_files': {
                'comprehensive_visualization': visualization_path,
                'detection_results_json': results_path,
                'final_panorama_image': final_panorama_path
            },
            'face_results': all_results,
            'panorama_bboxes': all_panorama_bboxes
        }
        
        print("\nğŸ‰ å…¨æ™¯å›¾åƒå˜åŒ–æ£€æµ‹å®Œæˆï¼")
        print(f"ğŸ“Š å¤„ç†ç»“æœæ‘˜è¦:")
        print(f"   â€¢ å¤„ç†ç«‹æ–¹ä½“é¢: {summary['total_faces_processed']}")
        print(f"   â€¢ æœ‰æ£€æµ‹ç»“æœçš„é¢: {summary['faces_with_detections']}")
        print(f"   â€¢ æ€»æ£€æµ‹åŒºåŸŸ: {summary['total_detection_count']}")
        print(f"   â€¢ å…¨æ™¯å›¾æ£€æµ‹æ¡†: {summary['panorama_bboxes_count']}")
        print(f"ğŸ“ ä¸»è¦è¾“å‡ºæ–‡ä»¶:")
        print(f"   â€¢ ç»¼åˆå¯è§†åŒ–: {os.path.basename(visualization_path)}")
        print(f"   â€¢ ç»“æœæ•°æ®: {os.path.basename(results_path)}")
        print(f"   â€¢ æœ€ç»ˆå…¨æ™¯å›¾: {os.path.basename(final_panorama_path)}")
        print(f"ğŸ“ è¯¦ç»†å¤„ç†æ­¥éª¤:")
        for result in all_results:
            if 'step_images_saved' in result:
                print(f"   â€¢ {result['face_name']} é¢æ­¥éª¤å›¾åƒ: {os.path.basename(result['step_images_saved'])}/")
        
        return summary


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºç³»ç»Ÿä½¿ç”¨"""
    # æµ‹è¯•å›¾åƒè·¯å¾„
    panorama1_path = os.path.join("test", "20250910164040_0002_V.jpeg")  # ç¬¬ä¸€æœŸå…¨æ™¯å›¾
    panorama2_path = os.path.join("test", "20250910164151_0003_V.jpeg")  # ç¬¬äºŒæœŸå…¨æ™¯å›¾
    
    # æ£€æŸ¥æµ‹è¯•å›¾åƒæ˜¯å¦å­˜åœ¨
    if not os.path.exists(panorama1_path) or not os.path.exists(panorama2_path):
        print("âŒ æµ‹è¯•å›¾åƒä¸å­˜åœ¨ï¼Œè¯·å°†å›¾åƒæ”¾å…¥ test/ ç›®å½•")
        print(f"éœ€è¦çš„å›¾åƒ:")
        print(f"  - {panorama1_path}")
        print(f"  - {panorama2_path}")
        return
    
    try:
        # åˆ›å»ºæ£€æµ‹ç³»ç»Ÿ
        system = PanoramaChangeDetectionSystem(
            output_dir="panorama_change_detection_results",
            use_cuda=True  # å°è¯•ä½¿ç”¨GPUåŠ é€Ÿ
        )
        
        # æ‰§è¡Œå®Œæ•´çš„æ£€æµ‹æµç¨‹
        results = system.process_panorama_pair(panorama1_path, panorama2_path)
        
        if results and results['processing_successful']:
            print("\nâœ… ç³»ç»Ÿè¿è¡ŒæˆåŠŸï¼")
            
            # å¯ä»¥ç»§ç»­è¿›è¡Œå…¶ä»–åˆ†æ...
            if results['total_detection_count'] > 0:
                print("ğŸ” å‘ç°å›¾åƒå˜åŒ–ï¼Œå»ºè®®è¿›ä¸€æ­¥äººå·¥å®¡æ ¸")
            else:
                print("ğŸ“ æœªå‘ç°æ˜¾è‘—å˜åŒ–ï¼Œå›¾åƒåŸºæœ¬ä¸€è‡´")
        else:
            print("âŒ ç³»ç»Ÿè¿è¡Œå¤±è´¥")
            
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 